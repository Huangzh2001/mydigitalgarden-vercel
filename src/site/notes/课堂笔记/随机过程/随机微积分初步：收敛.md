---
{"tags":["Notes","Math","StochasticProcess"],"version":1,"dg-publish":true,"permalink":"/课堂笔记/随机过程/随机微积分初步：收敛/","dgPassFrontmatter":true}
---

# 收敛

微积分有五个基本概念：极限、连续、求导、微分、积分。但归根结底只有一个概念，那就是极限。因为后面四个概念都是由极限定义而来的。

而定义极限的关键在于“距离”的选择，选择不同的距离就定义了不同的极限。所以，一旦我们选定了一个新的距离，一套新的微积分就诞生了。（距离是极限的灵魂，极限是微积分的核心）

下面我们选取不同的距离概念来定义随机变量的不同收敛：

设$X_n$是随机变量，则

```ad-definition
[四种收敛]

(1) 均方极限(Mean Square Distance):

$\forall\varepsilon>0,\exists N,\forall n>N,\mathrm{d}(X_{n},X)=(\mathbb{E}|X_{n}-X|^{2})^{\frac12}<\varepsilon$，记为$X_{n}\xrightarrow{m.s}X$

(2) 几乎处处收敛(Almost Sure Convergence/Almost Everywhere):

$P(\{w\in \Omega|X_n(w)\to X(w)\})=1$，记为$X_n\xrightarrow{a.s}X$

(3) 依概率收敛(Convergence in Probability):

$\forall\varepsilon>0,P(\{w:|X_{n}(w)-X(w)|\geq\varepsilon\})\rightarrow0(n\rightarrow\infty)$

(4) 依分布收敛(Convergence in Distribution)

设$\begin{cases}X_n\sim\mathrm{F}_{X_n}\left(x\right)=P\left(X_n\leq x\right)\\\mathrm{X}\sim\mathrm{F}_{X}\left(x\right)=P\left(X\leq x\right)\end{cases}$，则若在$F_X(x)$的连续点(continuous points)有$F_{X_{n}}(x)\xrightarrow{n\to\infty}F_{X}(x)$，则称$X_n$依分布收敛于$X$，记为$X_n\xrightarrow{F}X$。

```

这几个收敛之间的关系是什么？

## “均方极限”和“几乎处处收敛”之间没有包含关系

下面是两个例子：

(1)几乎处处收敛但不均方收敛的例子：

```ad-example
设$\Omega=[0,1],(\Omega,\sum,P)$，在其上定义Borel Probability为$P([c,d])=d-c$。构造随机变量$\{X_n\}:[0,1]\to \mathbb R$如下：

![](/img/user/课堂笔记/随机过程/attachments/随机微积分初步：收敛.png)

（其中$a=2^{\frac{1}{2}}$），则$X_{n}\xrightarrow{a.s}0,X_{n}\not\xrightarrow{m.s}0$
```

```ad-proof

(1) 证明$X_{n}\xrightarrow{a.s}0$

$\forall \omega\in (0,1],\exists N,\forall n>N,X_n(\omega)=0$。于是$X_{n}\xrightarrow{a.s}0$

(2) 证明$X_{n}\not\xrightarrow{m.s}0$

$$
\begin{aligned}
E|X_{n}(w)-0|^{2}& =E|X_{n}(w)|^{2}  \\
&=\int_{\Omega}|X_{n}(w)|^{2}P(dw) \\
&=\int_{\Omega}|X_{n}(w)|^{2}dw \\
&=\int_{0}^{1}|X_{n}(w)|^{2}dw \\
&=(\frac{1}{2})^{n}(a^{n})^{2} \\
&=(\frac{1}{2})^{n}2^{n}=1
\end{aligned}
$$

```

```ad-remark
但如果我们让随机变量有界，即$|X_n|\leq C$。几乎处处收敛就包含了均方收敛了。
```

(2)均方收敛但不几乎处处收敛的例子：（一个概率论里面著名的例子）

```ad-example
设$\Omega=[0,1],(\Omega,\sum,P)$，在其上定义Borel Probability为$P([c,d])=d-c$。构造随机变量$\{X_n\}:[0,1]\to \mathbb R$如下：

![](/img/user/课堂笔记/随机过程/attachments/随机微积分初步：收敛-1.png)

![](/img/user/课堂笔记/随机过程/attachments/随机微积分初步：收敛-2.png)

（发现其中的规律了吗？其实就是将[0,1]$2^n$等分，然后从左到右滑动），则$X_{n}\xrightarrow{m.s}0,X_{n}\not\xrightarrow{a.s}0$
```

```ad-proof

(1) 证明$X_{n}\xrightarrow{m.s}0$

（显然）

(2) 证明$X_{n}\not\xrightarrow{a.s}0$

$\forall \omega\in[0,1],\exists \varepsilon_0=0.5,\exists n>N,|X_n(\omega)|=1>0.5$（因为乌云不断地划过上空）

```

## 几乎处处收敛一定依概率收敛

```ad-proposition
几乎处处收敛一定依概率收敛
```

```ad-proof

(1) 
$P(\{w:X_{n}(w)\rightarrow X(w)\})=1\Longleftrightarrow P(\{w:X_{n}(w)\not\rightarrow X(w)\})=0$

(2) 然后将符号语言变成集合语言（这个操作学过实变函数的同学应该很熟悉，其实就是将$\forall$符号变成$\cup$，将$\exists$符号变成$\cap$）
$$
\begin{aligned}&\forall\varepsilon>0,\exists N,\forall n>N,P(\{w:X_n(w)\not\rightarrow X{(w)}\})=0\\&\Longleftrightarrow P(\bigcup_{\varepsilon>0}\bigcap_{N\in \mathbb N}\bigcup_{n>N}\{w:|X_n(w)-X(w)|\geq \varepsilon\})=0\end{aligned}
$$
(3) 剥洋葱
$$
\begin{aligned}
&P(\bigcup_{\varepsilon>0}\bigcap_{N\in\mathbb{N}}\bigcup_{n>N}\{w:|X_n(w)-X(w)|\geq\varepsilon\})=0\\
&\Longrightarrow\mathrm{~fixed~}\varepsilon,P(\bigcap_{N\in \mathbb N}\bigcup_{n>N}\{w:|X_{n}(w)-X(w)|\geq \varepsilon\})=0
\end{aligned}
$$
设$B_{N}=\bigcup_{n>N}\{w:|X_{n}(w)-X(w)|\geq\varepsilon\}$，我们观察到：
$$
B_{N}\supseteq B_{N+1}\supseteq B_{N+2}\supseteq\cdots 
$$
于是有：
$$
\begin{aligned}\Longrightarrow&\lim_{N\to\infty}P\left(\bigcup_{n> N}\left\{\left.w:|X_n(w)-X(w)\right|> \varepsilon\right\}\right)=0\\\Longrightarrow&\lim_{N\to\infty}P\left(\left\{\left.w:|X_{N+1}(w)-X(w)\right|\geq \varepsilon\right\}\right)\to0\end{aligned}
$$
```

依概率收敛不一定几乎处处收敛。例子就是前面的例子（这是个很神奇的例子）：

```ad-example
设$\Omega=[0,1],(\Omega,\sum,P)$，在其上定义Borel Probability为$P([c,d])=d-c$。构造随机变量$\{X_n\}:[0,1]\to \mathbb R$如下：

![](/img/user/课堂笔记/随机过程/attachments/随机微积分初步：收敛-3.png)

![](/img/user/课堂笔记/随机过程/attachments/随机微积分初步：收敛-4.png)

（发现其中的规律了吗？其实就是将[0,1]$2^n$等分，然后从左到右滑动）
```

## 依概率收敛一定依分布收敛

```ad-proposition
[依概率收敛一定依分布收敛]

$$
X_{n}\xrightarrow{p}X\Rightarrow X_{n}\xrightarrow{F}X
$$
```

```ad-proof

(1) 
$$
\begin{aligned}F_{X_n}(x)&=P(X_n\leq x)=P(X_n\leq x,X\in\mathbb{R})\\&=P(X_n\leq x,X>y)+P(X_n\leq x,X\leq y)\end{aligned}
$$
设$y>x$，则有$\{X_{n}\leq x,X> y\}\Rightarrow\{|X_{n}-X|>y-x\}$，即$\{X_{n}\leq x,X> y\}\subset\{|X_{n}-X|>y-x\}$。于是
$$
\leq P(|X_{n}-X|>y-x)+P(X\leq y)
$$
由于$X_{n}\xrightarrow{p}X$，所以有$P(|X_{n}-X|>y-x)\to0$。由于$P(X\leq y)=F_X(y)$。所以我们两边取上极限（上极限总存在），于是有：
$$
\underset{n}{\lim\sup} F_{X_n}(x)\leq F_{X}(y)
$$
(2) 如果我们证明了$F_{X}(z)\leq\underset{n}{\lim\inf }F_{X_n}(x)$。就有
$$
F_{X}(z)\leq\underset{n}{\lim\inf }F_{X_n}(x)\leq\underset{n}{\lim\sup} F_{X_n}(x)\leq F_{X}(y)
$$
这时只要我们两边令$z\to x,y\to x$，就可以由$x$是$F_X$的连续点可得$F_{X_n}(x)\to F_X(x)$。

(3) 下面我们来证明$F_{X}(z)\leq\underset{n}{\lim\inf }F_{X_n}(x)$。（其实我们只需在上述流程中用$X$代替$X_n$即可）
$$
F_{X}(z)=P(X\leq z)=P(X\leq z,X_{n}\in\mathbb{R})
$$
令$x>z$，则有
$$
\begin{aligned}&=P\left(X\leq z,X_n>x\right)+P\left(X\leq z,X_n\leq x\right)\\&\leq P\left(|X_n-X|>x-z\right)+P\left(X_n\leq x\right)\end{aligned}
$$
两边同时取下极限$\underset{n}{\lim\inf}$即可。
```

```ad-info
四种收敛总结：

![](/img/user/课堂笔记/随机过程/attachments/随机微积分初步：收敛-5.png)

四种收敛的区别在于收敛符号的位置。几乎处处的收敛符号作用在随机变量本身；依概率收敛作用在概率上；依分布收敛作用在分布上；均方收敛作用在矩上。

作用的位置离随机变量越近，“地位”越高。

我们发现依分布收敛是最弱的。比如$X\sim N(0,1)\Longleftrightarrow -X\sim N(0,1)$。

所以我们构造$X_n=(-1)^nX=\{X,-X,X,-X,\cdots\}$。则$X_n$依分布收敛，但不依概率，也不几乎处处，也不均方收敛。
```

# 大数定律

```ad-theorem
[大数定律的一般形式]

设$X_1,X_2,\cdots,X_n$独立同分布(i.i.d.)，$\frac{1}{n}(X_{1}+\cdots+X_{n})=\frac{1}{n}\sum_{k=1}^{n}X_{k}$，则
$$
\frac{1}{n}\sum_{k=1}^{n}X_{k}\xrightarrow{n\rightarrow\infty}E(X_{1})
$$
```

我们很好奇这里的收敛是指哪种收敛，毕竟我们在前面学过了四种随机变量的收敛。事实上，不同的收敛就是不同的大数定律：

$$
\begin{cases}
\text{均方收敛——超弱大数定律（辛钦大数定律）}\\ \\
\text{依概率收敛——弱大数定律(Weak Law of Large Numbers)}\\ \\
\text{几乎处处收敛——强大数定律(Strong Law of Large Numbers)}
\end{cases}
$$

## 超弱大数定律

```ad-theorem
[超弱大数定律]

设$X_1,X_2,\cdots,X_n$独立同分布(i.i.d.)，$\frac{1}{n}(X_{1}+\cdots+X_{n})=\frac{1}{n}\sum_{k=1}^{n}X_{k}$，则
$$
\frac{1}{n}\sum_{k=1}^{n}X_{k}\xrightarrow{m.s.}E(X_{1})
$$
```

```ad-proof
$$
\begin{aligned}
E\left|\frac{1}{n}\sum_{k=1}^{n}X_{k}-EX_{1}\right|^{2}&=\frac{1}{n^{2}}E\left|\sum_{k=1}^n\left(X_{k}-EX_{k}\right)\right|^{2}\\
&=\frac{1}{n^{2}}(\sum_{k=1}^{n}E|X_{k}-EX_{k}|^{2})+\frac{2}{n^{2}}\sum_{i\neq j}E\left|(X_{i}-EX_{i})(X_{j}-EX_{j})\right|\\
&=\frac{1}{n^{2}}\sum_{k=1}^{n}var(X_{k})\\
&=\frac{1}{n}\operatorname{var}\left(X_{1}\right)\xrightarrow{n\to\infty}0
\end{aligned}
$$
若$var(X_1)<\infty$，则有
$$
\frac{1}{n}\sum_{k=1}^{n}X_{k}\xrightarrow{m.s}E(X_{1})
$$
```

## 弱大数定律

```ad-lemma
[切比雪夫不等式]

$$
P(|X|\geq a)\leq\frac{E|X|^{2}}{a^{2}}
$$
```

```ad-proof
$$
\begin{aligned}
E|X|^{2}=\int_{\mathbb R}x^{2}f_{X}\left(x\right)dx&=\left(\int_{|x|\geq a}+\int_{|x|<a}\right)x^{2}f_{X}\left(x\right)dx\\
&\geq\int_{|x|\geq a}x^2f_X(x)dx\\&\geq\int_{|x|\geq a}a^2f_X(x)dx\\&=a^2P(|X|\geq a)
\end{aligned}
$$
```

```ad-corollary
$$
P(|X-EX|\geq a)\leq\frac{var(X)}{a^{2}}
$$
```

```ad-theorem
[弱大数定律]

设$X_1,X_2,\cdots,X_n$独立同分布(i.i.d.)，$\frac{1}{n}(X_{1}+\cdots+X_{n})=\frac{1}{n}\sum_{k=1}^{n}X_{k}$，则
$$
\frac{1}{n}\sum_{k=1}^{n}X_{k}\xrightarrow{P}E(X_{1})
$$
```

```ad-proof
$$
\begin{aligned}&P(|X-EX|\geq a)\leq\frac{\operatorname{var}(X)}{a^2}\\\Longrightarrow &P(|\frac1n\sum_{k=1}^nX_k-EX_1|\geq\varepsilon)\leq\frac1{\varepsilon^2}\frac1n\operatorname{var}(X_1)\xrightarrow{n\to\infty}0\end{aligned}
$$
```

```ad-proof
（第二种证明方法：特征函数.但只能证明依分布收敛,结论更弱）

特征函数的定义：$\phi_X(w)=E(\exp(jwX))=\int_{-\infty}^{+\infty}\exp\left(jwx\right)f_X(x)dx$

$$
\begin{aligned}
\phi_{\frac{X_{1}+\cdots+X_{n}}{n}}(w)& =E\left(\exp\left(jw\frac{X_{1}+\cdots+X_{n}}{n}\right)\right)  \\
&=E(\prod_{k=1}^n\exp(j\frac wnX_k)) \\
&=\prod_{k=1}^{n}E(\exp(j\frac{w}{n}X_{k})) \\
&=\left(\phi_{X_1}(\frac wn)\right)^n
\end{aligned}
$$
（其中倒数第二个等号是因为$X_i$之间相互独立）
$$
\begin{aligned}\left(\phi_{X_1}(\frac wn)\right)^n&=\left(E\left(\exp\left(j\frac wnX_1\right)\right)\right)^n\\&=\left(E\left(1+j\frac wnX_1+o\left(\frac1n\right)\right)\right)^n\\&=\left(1+j\frac wn\operatorname{E}(X_1)+0\left(\frac1n\right)\right)^n\\&\xrightarrow{n\to\infty}\exp\left(jw{E}(X_1)\right)=\phi_{E(X_1)}(w)\end{aligned}
$$

```

## 强大数定律

```ad-theorem

[强大数定律]

设$X_1,X_2,\cdots,X_n$独立同分布(i.i.d.)，$\frac{1}{n}(X_{1}+\cdots+X_{n})=\frac{1}{n}\sum_{k=1}^{n}X_{k}$，则
$$
\frac{1}{n}\sum_{k=1}^{n}X_{k}\xrightarrow{a.s.}E(X_{1})
$$
```

# 中心极限定理

```ad-theorem
[中心极限定理]

设$X_1,\cdots,X_n$是随机变量，且$E(X_k)=0$，$var(X_k)=1$，则
$$
\frac{1}{\sqrt{n}}\sum_{k=1}^{n}X_{k}\xrightarrow{F}N(0,1)
$$
```

```ad-proof
（证明跟大数定律的特征函数证明几乎完全一样，不同的是将分母的$n$换成$\sqrt{n}$，然后在泰勒展开中要多展一项，其他都完全相同）
$$
\begin{aligned}
\phi_{\frac{X_{1}+\cdots+X_{n}}{\sqrt{n}}}(w)& =E\left(\exp\left(jw\frac{X_{1}+\cdots+X_{n}}{\sqrt{n}}\right)\right)  \\
&=E(\prod_{k=1}^n\exp(j\frac{w}{\sqrt{n}}X_k)) \\
&=\prod_{k=1}^{n}E(\exp(j\frac{w}{\sqrt{n}}X_{k})) \\
&=\left(E\left(\exp\left(j\frac{w}{\sqrt{n}}X_{1}\right)\right)\right)^{n}\\
&=\left(\mathrm{E}\left(1+j\frac{w}{\sqrt{n}}X_{1}+\frac{1}{2}\left(\frac{w}{\sqrt{n}}X_{1}\right)^{2}+o\left(\frac{1}{n}\right)\right)\right)^{n}\\
&=\left(1+j\frac{w}{\sqrt{n}}E(X_{1})+\frac{1}{2}E\left(j\frac{w}{\sqrt{n}}X_{1}\right)^{2}+o(\frac{1}{n})\right)^{n}\\
&=\left(1-\frac{w^2}{2n}E\left(X_{1}{}^2\right)+o(\frac1n)\right)^n\\&=\left(1-\frac{w^2}{2n}+o(\frac1n)\right)^n\\
&\xrightarrow{n\to\infty}\exp(-\frac{w^{2}}{2})
\end{aligned}
$$
而$N(0,1)\sim\frac1{\sqrt{2\pi}}\exp(-\frac{x^2}2)$，所以证毕.
```

# 重对数律

通过大数定律和中心极限定理，我们发现：
$$
\begin{aligned}
&\frac{1}{n}\sum_{k=1}^{n}X_{k}\xrightarrow{n\rightarrow\infty}E(X_{1})\\
&\frac{1}{\sqrt{n}}\sum_{k=1}^{n}X_{k}\xrightarrow{n\rightarrow\infty}N(0,1)
\end{aligned}
$$

即除以$n$就将$\sum_{k=1}^{n}X_{k}$的不确定性完全消解掉了，变成一个常数了；而除以$\sqrt{n}$则还保有一定的不确定性，但这个不确定性的种类很单一了，只能是高斯了。我们进一步思考：从$\sqrt{n}$到$n$是否存在一个临界值，使得除以它的不确定性刚刚好就被完全消除。事实上，这个临界值已经被完全搞清楚了，是
$$
\sqrt{n\ln\ln n}
$$

这个结论非常漂亮，被钟开莱称为“经典概率论王冠般的成就”。这意味着我们人类对独立的随机变量的规律已经完全掌握了。

```ad-theorem
[重对数律(Law of the iterated logarithm)]

设$X_1,\cdots,X_n$是均值为0，方差为1的独立同分布的随机变量，则有
$$
\operatorname*{\overline{lim}}_{n\to\infty}\frac{\sum_{i=1}^nX_i}{\left(2n\log\left(\log n\right)\right)^{1/2}}=1\quad a.s.
$$
```
